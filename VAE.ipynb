{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"VAE_tensorflow.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7SkM-cjawB0M","executionInfo":{"status":"ok","timestamp":1647306165875,"user_tz":420,"elapsed":857,"user":{"displayName":"ANDREA CASASSA SIAN","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05004144499949693318"}},"outputId":"bced577a-4d82-47da-c389-62658c76485f"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["cd drive/MyDrive/C247Project/project/"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5WlO8ABjwG5y","executionInfo":{"status":"ok","timestamp":1647306165877,"user_tz":420,"elapsed":18,"user":{"displayName":"ANDREA CASASSA SIAN","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05004144499949693318"}},"outputId":"8c57b052-95b8-4479-c7f9-816700284ae8"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/.shortcut-targets-by-id/1lO_lCKfnzu9fB3MDutIRFUOktcz9B9el/C247Project/project\n"]}]},{"cell_type":"code","source":["!pip install tensorflow"],"metadata":{"id":"hcFQfBDoxgRC","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1647306173644,"user_tz":420,"elapsed":7773,"user":{"displayName":"ANDREA CASASSA SIAN","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05004144499949693318"}},"outputId":"5383c34a-9148-43c9-d44a-8c805df0c552"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (2.8.0)\n","Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.2)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow) (57.4.0)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.13.3)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.3.0)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.1.0)\n","Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.0.0)\n","Requirement already satisfied: tf-estimator-nightly==2.8.0.dev2021122109 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0.dev2021122109)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.6.3)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.10.0.2)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.2.0)\n","Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (13.0.0)\n","Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.15.0)\n","Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.17.3)\n","Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.5.3)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.44.0)\n","Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.0)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.24.0)\n","Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n","Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.21.5)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n","Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow) (1.5.2)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.35.0)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.8.1)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (3.3.6)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.4.6)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.23.0)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.0.1)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.6.1)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.2.8)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.8)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.2.4)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (1.3.1)\n","Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (4.11.2)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (3.7.0)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.4.8)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2021.10.8)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (3.2.0)\n"]}]},{"cell_type":"code","execution_count":4,"metadata":{"id":"YBGpJnDTv3L3","executionInfo":{"status":"ok","timestamp":1647306180013,"user_tz":420,"elapsed":6377,"user":{"displayName":"ANDREA CASASSA SIAN","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05004144499949693318"}}},"outputs":[],"source":["from tensorflow.keras.metrics import categorical_accuracy\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Permute, Bidirectional, BatchNormalization, Conv2D, LSTM, Dense, Dropout, ELU, Flatten, MaxPool2D, TimeDistributed, Dense\n","from tensorflow.keras.regularizers import L1L2\n","from tensorflow.keras.utils import to_categorical\n","from tensorflow.keras.initializers import lecun_uniform\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras import layers\n","from tensorflow.keras.layers import Lambda, Input, ReLU, Reshape, Conv2DTranspose\n","from tensorflow.keras import backend as UT\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.losses import mse\n","import tensorflow as tf\n","from tensorflow import keras\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import time"]},{"cell_type":"code","source":["tf.test.gpu_device_name()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":37},"id":"c5A3czb7o7DC","executionInfo":{"status":"ok","timestamp":1647306180870,"user_tz":420,"elapsed":11,"user":{"displayName":"ANDREA CASASSA SIAN","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05004144499949693318"}},"outputId":"c354b4b3-4ae8-4415-bbaf-7105ad1a3ebc"},"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/device:GPU:0'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":5}]},{"cell_type":"markdown","source":["## Import Datasets"],"metadata":{"id":"tSHheIejwaVJ"}},{"cell_type":"code","source":["X_test = np.load(\"Dataset/X_test.npy\")\n","y_test = np.load(\"Dataset/y_test.npy\")\n","person_train_valid = np.load(\"Dataset/person_train_valid.npy\")\n","X_train_valid = np.load(\"Dataset/X_train_valid.npy\")\n","y_train_valid = np.load(\"Dataset/y_train_valid.npy\")\n","person_test = np.load(\"Dataset/person_test.npy\")\n","\n","y_train_valid -= 769\n","y_test -= 769"],"metadata":{"id":"Ot7S68-dwcNy","executionInfo":{"status":"ok","timestamp":1647306182132,"user_tz":420,"elapsed":1267,"user":{"displayName":"ANDREA CASASSA SIAN","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05004144499949693318"}}},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":["##Shape of Data"],"metadata":{"id":"Zd0LMVelwtfl"}},{"cell_type":"code","source":["print ('Training/Valid data shape: {}'.format(X_train_valid.shape))\n","print ('Test data shape: {}'.format(X_test.shape))\n","print ('Training/Valid target shape: {}'.format(y_train_valid.shape))\n","print ('Test target shape: {}'.format(y_test.shape))\n","print ('Person train/valid shape: {}'.format(person_train_valid.shape))\n","print ('Person test shape: {}'.format(person_test.shape))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Cw6wW1Z8EDEH","executionInfo":{"status":"ok","timestamp":1647306182133,"user_tz":420,"elapsed":12,"user":{"displayName":"ANDREA CASASSA SIAN","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05004144499949693318"}},"outputId":"3ef8a4d4-6021-4d80-f5e3-33de3effb865"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Training/Valid data shape: (2115, 22, 1000)\n","Test data shape: (443, 22, 1000)\n","Training/Valid target shape: (2115,)\n","Test target shape: (443,)\n","Person train/valid shape: (2115, 1)\n","Person test shape: (443, 1)\n"]}]},{"cell_type":"markdown","source":["## VAE"],"metadata":{"id":"_yJUrYhI3YnZ"}},{"cell_type":"code","source":["## Variables\n","\n","batch_size = 64\n","kernel_size = 5\n","filters_1 = 32\n","filters_2 = 64\n","hidden_dim = 2\n","epochs = 50\n","\n","X_VAE_train = X_train_valid.reshape(X_train_valid.shape[0], X_train_valid.shape[1], X_train_valid.shape[2], 1).astype('float32')\n","X_VAE_test = X_test.reshape(X_test.shape[0], X_test.shape[1], X_test.shape[2], 1).astype('float32')\n","\n","input_shape = (batch_size,22,1000,1)\n","print(input_shape[1:])\n"],"metadata":{"id":"okv3Xzjlqsam","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1647307798401,"user_tz":420,"elapsed":320,"user":{"displayName":"ANDREA CASASSA SIAN","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05004144499949693318"}},"outputId":"58e10839-be87-4ed6-ab12-b61b6d3a7d3c"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["(22, 1000, 1)\n"]}]},{"cell_type":"code","source":["def sampling(in_1,in_2):\n","\n","  z_mean = in_1\n","  z_log_var = in_2\n","  out = layers.Lambda(sampling_reparameterization)([z_mean, z_log_var])\n","  return out\n","\n","def sampling_reparameterization(params):\n","\n","  z_mean, z_log_var = params\n","  epsilon = UT.random_normal(shape=UT.shape(z_mean), mean=0., stddev=1.)\n","  z = z_mean + UT.exp(z_log_var / 2) * epsilon\n","  return z"],"metadata":{"id":"ANq7v6-YDpPo","executionInfo":{"status":"ok","timestamp":1647306182313,"user_tz":420,"elapsed":8,"user":{"displayName":"ANDREA CASASSA SIAN","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05004144499949693318"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["def VAE(input_shape):\n","\n","  ##############\n","  ## ENCODER ##\n","  #############\n","\n","  inputs = keras.Input(shape=input_shape[1:],batch_size=None)\n","  x = inputs\n","\n","  #Block1\n","  x = layers.Conv2D(filters_1,kernel_size=(1,40),strides=(1,20))(x)\n","  #x = layers.BatchNormalization()(x)\n","  x = layers.LeakyReLU()(x)\n","\n","  #Block2\n","  x = layers.Conv2D(filters_2,kernel_size=(22,1))(x)\n","  #x = layers.BatchNormalization()(x)\n","  x = layers.LeakyReLU()(x)\n","\n","  #shape = 1,49,64\n","  useful_shape = UT.int_shape(x)\n","\n","  #Final block\n","  x = layers.Flatten()(x)\n","  x = layers.Dense(16,activation='relu')(x)\n","\n","  z_mean = layers.Dense(hidden_dim)(x)\n","  z_log_var = layers.Dense(hidden_dim)(x)\n","  z_log_var += 1e-6 #add a small epsilon so that it's not zero\n","\n","  ###############\n","  ## SAMPLING ##\n","  ##############\n","\n","  latent = sampling(z_mean, z_log_var)\n","\n","  ##############\n","  ## DECODER ##\n","  #############\n","\n","  x = latent\n","\n","  #Initial block\n","  x = layers.Dense(1*49*64, activation='relu')(x)\n","  x = layers.Reshape((1,49,64))(x)\n","\n","  # Block1\n","  x = layers.Conv2DTranspose(filters_2, kernel_size=(22,1))(x)\n","  #x = layers.BatchNormalization()(x)\n","  x = layers.LeakyReLU()(x)\n","\n","  #Block2\n","  x = layers.Conv2DTranspose(filters_1, kernel_size=(1,40), strides= (1,20))(x)\n","  #x = layers.BatchNormalization()(x)\n","  x = layers.LeakyReLU()(x)\n","\n","  #Final block\n","  out = layers.Conv2DTranspose(1, kernel_size=kernel_size, strides=1,padding='same')(x)\n","\n","  ##############\n","  #### VAE ####\n","  #############\n","\n","  vae = tf.keras.Model(inputs,out,name=\"vae\")\n","  vae.summary()\n","\n","  return (vae,inputs,out,z_mean,z_log_var)"],"metadata":{"id":"uzORKIblAefD","executionInfo":{"status":"ok","timestamp":1647306182472,"user_tz":420,"elapsed":5,"user":{"displayName":"ANDREA CASASSA SIAN","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05004144499949693318"}}},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":["## Loss function"],"metadata":{"id":"GRn4Kts7o_Ha"}},{"cell_type":"code","source":["def mse_loss(y_true, y_pred):\n","    r_loss = UT.mean(UT.square(y_true - y_pred), axis = [1,2,3])\n","    #Multiply it by the time length and the channels\n","    return 1000 * 22 * r_loss \n"," \n","def kl_loss(mean, log_var):\n","    kl_loss =  -0.5 * UT.sum(1 + log_var - UT.square(mean) - UT.exp(log_var), axis = -1)\n","    return kl_loss\n","\n","def vae_loss(y_true, y_pred, mean, var):\n","    r_loss = mse_loss(y_true, y_pred)\n","    k_loss = kl_loss(mean, var)\n","    return  UT.mean(r_loss + k_loss)"],"metadata":{"id":"s9mWidonmV2S","executionInfo":{"status":"ok","timestamp":1647307804798,"user_tz":420,"elapsed":108,"user":{"displayName":"ANDREA CASASSA SIAN","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05004144499949693318"}}},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":["## Training"],"metadata":{"id":"5hdYOl62nTEw"}},{"cell_type":"code","source":["def train(dataset, epochs):\n","\n","  vae, inputs, out, mean, log_var = VAE(input_shape)\n","  loss = vae_loss(inputs, out, mean, log_var)\n","  optimizer = tf.keras.optimizers.Adam(learning_rate = 0.001,beta_1=0.1, beta_2=0.999)\n","  vae.add_loss(loss)\n","  vae.compile(loss=None, optimizer=optimizer)  \n","  vae.fit(x=X_VAE_train,y=X_VAE_train,epochs=epochs, batch_size=batch_size,validation_data=(X_VAE_test,None))\n","\n","  return vae"],"metadata":{"id":"Dg1GId7Dma2S","executionInfo":{"status":"ok","timestamp":1647307813216,"user_tz":420,"elapsed":119,"user":{"displayName":"ANDREA CASASSA SIAN","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05004144499949693318"}}},"execution_count":24,"outputs":[]},{"cell_type":"code","source":["vae = train(X_VAE_train, epochs)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vM8yCm13mf0-","executionInfo":{"status":"ok","timestamp":1647307971214,"user_tz":420,"elapsed":151277,"user":{"displayName":"ANDREA CASASSA SIAN","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05004144499949693318"}},"outputId":"38cdccf0-c428-487b-f3c0-08fd584a83be"},"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"vae\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," input_16 (InputLayer)          [(None, 22, 1000, 1  0           []                               \n","                                )]                                                                \n","                                                                                                  \n"," conv2d_30 (Conv2D)             (None, 22, 49, 32)   1312        ['input_16[0][0]']               \n","                                                                                                  \n"," leaky_re_lu_60 (LeakyReLU)     (None, 22, 49, 32)   0           ['conv2d_30[0][0]']              \n","                                                                                                  \n"," conv2d_31 (Conv2D)             (None, 1, 49, 64)    45120       ['leaky_re_lu_60[0][0]']         \n","                                                                                                  \n"," leaky_re_lu_61 (LeakyReLU)     (None, 1, 49, 64)    0           ['conv2d_31[0][0]']              \n","                                                                                                  \n"," flatten_15 (Flatten)           (None, 3136)         0           ['leaky_re_lu_61[0][0]']         \n","                                                                                                  \n"," dense_60 (Dense)               (None, 16)           50192       ['flatten_15[0][0]']             \n","                                                                                                  \n"," dense_62 (Dense)               (None, 2)            34          ['dense_60[0][0]']               \n","                                                                                                  \n"," dense_61 (Dense)               (None, 2)            34          ['dense_60[0][0]']               \n","                                                                                                  \n"," tf.__operators__.add_45 (TFOpL  (None, 2)           0           ['dense_62[0][0]']               \n"," ambda)                                                                                           \n","                                                                                                  \n"," lambda_15 (Lambda)             (None, 2)            0           ['dense_61[0][0]',               \n","                                                                  'tf.__operators__.add_45[0][0]']\n","                                                                                                  \n"," dense_63 (Dense)               (None, 3136)         9408        ['lambda_15[0][0]']              \n","                                                                                                  \n"," reshape_15 (Reshape)           (None, 1, 49, 64)    0           ['dense_63[0][0]']               \n","                                                                                                  \n"," conv2d_transpose_45 (Conv2DTra  (None, 22, 49, 64)  90176       ['reshape_15[0][0]']             \n"," nspose)                                                                                          \n","                                                                                                  \n"," leaky_re_lu_62 (LeakyReLU)     (None, 22, 49, 64)   0           ['conv2d_transpose_45[0][0]']    \n","                                                                                                  \n"," conv2d_transpose_46 (Conv2DTra  (None, 22, 1000, 32  81952      ['leaky_re_lu_62[0][0]']         \n"," nspose)                        )                                                                 \n","                                                                                                  \n"," leaky_re_lu_63 (LeakyReLU)     (None, 22, 1000, 32  0           ['conv2d_transpose_46[0][0]']    \n","                                )                                                                 \n","                                                                                                  \n"," conv2d_transpose_47 (Conv2DTra  (None, 22, 1000, 1)  801        ['leaky_re_lu_63[0][0]']         \n"," nspose)                                                                                          \n","                                                                                                  \n","==================================================================================================\n","Total params: 279,029\n","Trainable params: 279,029\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n","Epoch 1/50\n","34/34 [==============================] - 4s 97ms/step - loss: 40919648.0000 - val_loss: 2555394.7500\n","Epoch 2/50\n","34/34 [==============================] - 3s 87ms/step - loss: 2498178.2500 - val_loss: 2528798.5000\n","Epoch 3/50\n","34/34 [==============================] - 3s 84ms/step - loss: 2525612.7500 - val_loss: 2514719.2500\n","Epoch 4/50\n","34/34 [==============================] - 3s 88ms/step - loss: 2474469.2500 - val_loss: 2504413.2500\n","Epoch 5/50\n","34/34 [==============================] - 3s 88ms/step - loss: 2478173.2500 - val_loss: 2497780.5000\n","Epoch 6/50\n","34/34 [==============================] - 3s 84ms/step - loss: 2487678.7500 - val_loss: 2492938.5000\n","Epoch 7/50\n","34/34 [==============================] - 3s 88ms/step - loss: 2480167.0000 - val_loss: 2489028.2500\n","Epoch 8/50\n","34/34 [==============================] - 3s 85ms/step - loss: 2456726.2500 - val_loss: 2485667.2500\n","Epoch 9/50\n","34/34 [==============================] - 3s 88ms/step - loss: 2438515.2500 - val_loss: 2481957.7500\n","Epoch 10/50\n","34/34 [==============================] - 3s 88ms/step - loss: 2458758.5000 - val_loss: 2479282.2500\n","Epoch 11/50\n","34/34 [==============================] - 3s 86ms/step - loss: 2444149.2500 - val_loss: 2476453.2500\n","Epoch 12/50\n","34/34 [==============================] - 3s 86ms/step - loss: 2480397.5000 - val_loss: 2475293.7500\n","Epoch 13/50\n","34/34 [==============================] - 3s 89ms/step - loss: 2428124.0000 - val_loss: 2471020.5000\n","Epoch 14/50\n","34/34 [==============================] - 3s 88ms/step - loss: 2458538.7500 - val_loss: 2467668.0000\n","Epoch 15/50\n","34/34 [==============================] - 3s 85ms/step - loss: 2447410.7500 - val_loss: 2465375.7500\n","Epoch 16/50\n","34/34 [==============================] - 3s 89ms/step - loss: 2441335.0000 - val_loss: 2462486.7500\n","Epoch 17/50\n","34/34 [==============================] - 3s 89ms/step - loss: 2445806.0000 - val_loss: 2465321.5000\n","Epoch 18/50\n","34/34 [==============================] - 3s 86ms/step - loss: 2450389.7500 - val_loss: 2461398.7500\n","Epoch 19/50\n","34/34 [==============================] - 3s 86ms/step - loss: 2431400.2500 - val_loss: 2457559.5000\n","Epoch 20/50\n","34/34 [==============================] - 3s 86ms/step - loss: 2475803.2500 - val_loss: 2456898.2500\n","Epoch 21/50\n","34/34 [==============================] - 3s 86ms/step - loss: 2423931.7500 - val_loss: 2455324.2500\n","Epoch 22/50\n","34/34 [==============================] - 3s 88ms/step - loss: 2428377.7500 - val_loss: 2454363.5000\n","Epoch 23/50\n","34/34 [==============================] - 3s 85ms/step - loss: 2436878.0000 - val_loss: 2453351.2500\n","Epoch 24/50\n","34/34 [==============================] - 3s 89ms/step - loss: 2444119.7500 - val_loss: 2453820.0000\n","Epoch 25/50\n","34/34 [==============================] - 3s 89ms/step - loss: 2456855.7500 - val_loss: 2453590.0000\n","Epoch 26/50\n","34/34 [==============================] - 3s 88ms/step - loss: 2412694.7500 - val_loss: 2451515.7500\n","Epoch 27/50\n","34/34 [==============================] - 3s 86ms/step - loss: 2422137.5000 - val_loss: 2451280.7500\n","Epoch 28/50\n","34/34 [==============================] - 3s 86ms/step - loss: 2428900.7500 - val_loss: 2450268.5000\n","Epoch 29/50\n","34/34 [==============================] - 3s 86ms/step - loss: 2430813.7500 - val_loss: 2449308.0000\n","Epoch 30/50\n","34/34 [==============================] - 3s 88ms/step - loss: 2448588.7500 - val_loss: 2449232.5000\n","Epoch 31/50\n","34/34 [==============================] - 3s 89ms/step - loss: 2480048.5000 - val_loss: 2449449.5000\n","Epoch 32/50\n","34/34 [==============================] - 3s 86ms/step - loss: 2405174.5000 - val_loss: 2448120.2500\n","Epoch 33/50\n","34/34 [==============================] - 3s 89ms/step - loss: 2491844.7500 - val_loss: 2446996.5000\n","Epoch 34/50\n","34/34 [==============================] - 3s 89ms/step - loss: 2438957.5000 - val_loss: 2446859.2500\n","Epoch 35/50\n","34/34 [==============================] - 3s 85ms/step - loss: 2419510.2500 - val_loss: 2446774.7500\n","Epoch 36/50\n","34/34 [==============================] - 3s 90ms/step - loss: 2416154.0000 - val_loss: 2445887.2500\n","Epoch 37/50\n","34/34 [==============================] - 3s 89ms/step - loss: 2420047.2500 - val_loss: 2445617.2500\n","Epoch 38/50\n","34/34 [==============================] - 3s 86ms/step - loss: 2419306.7500 - val_loss: 2445898.0000\n","Epoch 39/50\n","34/34 [==============================] - 3s 86ms/step - loss: 2435904.2500 - val_loss: 2444395.5000\n","Epoch 40/50\n","34/34 [==============================] - 3s 86ms/step - loss: 2440846.5000 - val_loss: 2443906.2500\n","Epoch 41/50\n","34/34 [==============================] - 3s 86ms/step - loss: 2405561.2500 - val_loss: 2443731.5000\n","Epoch 42/50\n","34/34 [==============================] - 3s 85ms/step - loss: 2433076.7500 - val_loss: 2443565.2500\n","Epoch 43/50\n","34/34 [==============================] - 3s 86ms/step - loss: 2430926.0000 - val_loss: 2442952.5000\n","Epoch 44/50\n","34/34 [==============================] - 3s 86ms/step - loss: 2433762.5000 - val_loss: 2443494.7500\n","Epoch 45/50\n","34/34 [==============================] - 3s 86ms/step - loss: 2455392.2500 - val_loss: 2442721.2500\n","Epoch 46/50\n","34/34 [==============================] - 3s 85ms/step - loss: 2437463.7500 - val_loss: 2443099.5000\n","Epoch 47/50\n","34/34 [==============================] - 3s 88ms/step - loss: 2426803.2500 - val_loss: 2444473.2500\n","Epoch 48/50\n","34/34 [==============================] - 3s 86ms/step - loss: 2426733.7500 - val_loss: 2441849.7500\n","Epoch 49/50\n","34/34 [==============================] - 3s 89ms/step - loss: 2391796.2500 - val_loss: 2440754.7500\n","Epoch 50/50\n","34/34 [==============================] - 3s 86ms/step - loss: 2437205.0000 - val_loss: 2440730.0000\n"]}]},{"cell_type":"markdown","source":["## Hyperparameters tuning"],"metadata":{"id":"RNLcOBPDoQBt"}},{"cell_type":"code","source":["from sklearn.metrics import mean_squared_error\n","\n","lrs = [0.001,0.0004,0.0006]\n","bs = [32,64,128]\n","scores = []\n","\n","m = tf.keras.metrics.MeanSquaredError()\n","\n","for lr in lrs:\n","  for b in bs:\n","\n","    vae, inputs, out, mean, log_var = VAE(input_shape)\n","    loss = vae_loss(inputs, out, mean, log_var)\n","    optimizer = tf.keras.optimizers.Adam(learning_rate = lr,beta_1=0.1, beta_2=0.999)\n","    vae.add_loss(loss)\n","    vae.compile(loss=None, optimizer=optimizer)  \n","    vae.fit(x=X_VAE_train,y=X_VAE_train,epochs=30, batch_size=b,validation_data=(X_VAE_test,None))\n","    pred = vae.predict(X_VAE_train)\n","    score = m(X_VAE_train,pred).numpy()\n","    scores.append((lr,b,score))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OJTysez-oPBs","executionInfo":{"status":"ok","timestamp":1647307401828,"user_tz":420,"elapsed":1054209,"user":{"displayName":"ANDREA CASASSA SIAN","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05004144499949693318"}},"outputId":"3ff22d93-0ca6-4eca-a419-66f3cf78e32b"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"vae\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," input_7 (InputLayer)           [(None, 22, 1000, 1  0           []                               \n","                                )]                                                                \n","                                                                                                  \n"," conv2d_12 (Conv2D)             (None, 22, 49, 32)   1312        ['input_7[0][0]']                \n","                                                                                                  \n"," leaky_re_lu_24 (LeakyReLU)     (None, 22, 49, 32)   0           ['conv2d_12[0][0]']              \n","                                                                                                  \n"," conv2d_13 (Conv2D)             (None, 1, 49, 64)    45120       ['leaky_re_lu_24[0][0]']         \n","                                                                                                  \n"," leaky_re_lu_25 (LeakyReLU)     (None, 1, 49, 64)    0           ['conv2d_13[0][0]']              \n","                                                                                                  \n"," flatten_6 (Flatten)            (None, 3136)         0           ['leaky_re_lu_25[0][0]']         \n","                                                                                                  \n"," dense_24 (Dense)               (None, 16)           50192       ['flatten_6[0][0]']              \n","                                                                                                  \n"," dense_26 (Dense)               (None, 2)            34          ['dense_24[0][0]']               \n","                                                                                                  \n"," dense_25 (Dense)               (None, 2)            34          ['dense_24[0][0]']               \n","                                                                                                  \n"," tf.__operators__.add_18 (TFOpL  (None, 2)           0           ['dense_26[0][0]']               \n"," ambda)                                                                                           \n","                                                                                                  \n"," lambda_6 (Lambda)              (None, 2)            0           ['dense_25[0][0]',               \n","                                                                  'tf.__operators__.add_18[0][0]']\n","                                                                                                  \n"," dense_27 (Dense)               (None, 3136)         9408        ['lambda_6[0][0]']               \n","                                                                                                  \n"," reshape_6 (Reshape)            (None, 1, 49, 64)    0           ['dense_27[0][0]']               \n","                                                                                                  \n"," conv2d_transpose_18 (Conv2DTra  (None, 22, 49, 64)  90176       ['reshape_6[0][0]']              \n"," nspose)                                                                                          \n","                                                                                                  \n"," leaky_re_lu_26 (LeakyReLU)     (None, 22, 49, 64)   0           ['conv2d_transpose_18[0][0]']    \n","                                                                                                  \n"," conv2d_transpose_19 (Conv2DTra  (None, 22, 1000, 32  81952      ['leaky_re_lu_26[0][0]']         \n"," nspose)                        )                                                                 \n","                                                                                                  \n"," leaky_re_lu_27 (LeakyReLU)     (None, 22, 1000, 32  0           ['conv2d_transpose_19[0][0]']    \n","                                )                                                                 \n","                                                                                                  \n"," conv2d_transpose_20 (Conv2DTra  (None, 22, 1000, 1)  801        ['leaky_re_lu_27[0][0]']         \n"," nspose)                                                                                          \n","                                                                                                  \n","==================================================================================================\n","Total params: 279,029\n","Trainable params: 279,029\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n","Epoch 1/30\n","67/67 [==============================] - 5s 54ms/step - loss: 2507770.7500 - val_loss: 2450327.2500\n","Epoch 2/30\n","67/67 [==============================] - 3s 46ms/step - loss: 2433230.2500 - val_loss: 2433730.0000\n","Epoch 3/30\n","67/67 [==============================] - 3s 48ms/step - loss: 2416129.7500 - val_loss: 2427683.2500\n","Epoch 4/30\n","67/67 [==============================] - 3s 46ms/step - loss: 2433651.0000 - val_loss: 2466093.2500\n","Epoch 5/30\n","67/67 [==============================] - 3s 48ms/step - loss: 2440616.2500 - val_loss: 2438576.5000\n","Epoch 6/30\n","67/67 [==============================] - 3s 47ms/step - loss: 2406455.2500 - val_loss: 2441357.7500\n","Epoch 7/30\n","67/67 [==============================] - 3s 47ms/step - loss: 2410313.7500 - val_loss: 2438992.7500\n","Epoch 8/30\n","67/67 [==============================] - 3s 48ms/step - loss: 2406877.7500 - val_loss: 2430777.2500\n","Epoch 9/30\n","67/67 [==============================] - 3s 47ms/step - loss: 2428577.7500 - val_loss: 2448080.2500\n","Epoch 10/30\n","67/67 [==============================] - 3s 46ms/step - loss: 2400460.7500 - val_loss: 2438394.5000\n","Epoch 11/30\n","67/67 [==============================] - 3s 47ms/step - loss: 2432666.2500 - val_loss: 2432168.0000\n","Epoch 12/30\n","67/67 [==============================] - 3s 48ms/step - loss: 2401166.7500 - val_loss: 2440263.5000\n","Epoch 13/30\n","67/67 [==============================] - 3s 48ms/step - loss: 2404930.7500 - val_loss: 2443288.7500\n","Epoch 14/30\n","67/67 [==============================] - 3s 48ms/step - loss: 2396035.2500 - val_loss: 2433723.5000\n","Epoch 15/30\n","67/67 [==============================] - 3s 47ms/step - loss: 2398824.0000 - val_loss: 2430984.5000\n","Epoch 16/30\n","67/67 [==============================] - 3s 48ms/step - loss: 2394832.2500 - val_loss: 2433142.0000\n","Epoch 17/30\n","67/67 [==============================] - 3s 48ms/step - loss: 2403885.0000 - val_loss: 2431131.5000\n","Epoch 18/30\n","67/67 [==============================] - 3s 48ms/step - loss: 2404166.7500 - val_loss: 2436790.7500\n","Epoch 19/30\n","67/67 [==============================] - 3s 47ms/step - loss: 2400549.2500 - val_loss: 2432792.0000\n","Epoch 20/30\n","67/67 [==============================] - 3s 48ms/step - loss: 2409345.7500 - val_loss: 2444775.7500\n","Epoch 21/30\n","67/67 [==============================] - 3s 47ms/step - loss: 2397373.2500 - val_loss: 2431151.7500\n","Epoch 22/30\n","67/67 [==============================] - 3s 48ms/step - loss: 2403124.7500 - val_loss: 2434036.2500\n","Epoch 23/30\n","67/67 [==============================] - 3s 48ms/step - loss: 2408493.7500 - val_loss: 2432895.7500\n","Epoch 24/30\n","67/67 [==============================] - 3s 50ms/step - loss: 2384766.0000 - val_loss: 2427944.7500\n","Epoch 25/30\n","67/67 [==============================] - 3s 47ms/step - loss: 2395732.5000 - val_loss: 2432873.7500\n","Epoch 26/30\n","67/67 [==============================] - 3s 48ms/step - loss: 2386249.5000 - val_loss: 2430434.5000\n","Epoch 27/30\n","67/67 [==============================] - 3s 48ms/step - loss: 2386482.0000 - val_loss: 2438682.5000\n","Epoch 28/30\n","67/67 [==============================] - 3s 47ms/step - loss: 2404823.2500 - val_loss: 2434277.7500\n","Epoch 29/30\n","67/67 [==============================] - 3s 48ms/step - loss: 2386004.0000 - val_loss: 2432190.5000\n","Epoch 30/30\n","67/67 [==============================] - 3s 48ms/step - loss: 2403869.5000 - val_loss: 2451590.5000\n","Model: \"vae\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," input_8 (InputLayer)           [(None, 22, 1000, 1  0           []                               \n","                                )]                                                                \n","                                                                                                  \n"," conv2d_14 (Conv2D)             (None, 22, 49, 32)   1312        ['input_8[0][0]']                \n","                                                                                                  \n"," leaky_re_lu_28 (LeakyReLU)     (None, 22, 49, 32)   0           ['conv2d_14[0][0]']              \n","                                                                                                  \n"," conv2d_15 (Conv2D)             (None, 1, 49, 64)    45120       ['leaky_re_lu_28[0][0]']         \n","                                                                                                  \n"," leaky_re_lu_29 (LeakyReLU)     (None, 1, 49, 64)    0           ['conv2d_15[0][0]']              \n","                                                                                                  \n"," flatten_7 (Flatten)            (None, 3136)         0           ['leaky_re_lu_29[0][0]']         \n","                                                                                                  \n"," dense_28 (Dense)               (None, 16)           50192       ['flatten_7[0][0]']              \n","                                                                                                  \n"," dense_30 (Dense)               (None, 2)            34          ['dense_28[0][0]']               \n","                                                                                                  \n"," dense_29 (Dense)               (None, 2)            34          ['dense_28[0][0]']               \n","                                                                                                  \n"," tf.__operators__.add_21 (TFOpL  (None, 2)           0           ['dense_30[0][0]']               \n"," ambda)                                                                                           \n","                                                                                                  \n"," lambda_7 (Lambda)              (None, 2)            0           ['dense_29[0][0]',               \n","                                                                  'tf.__operators__.add_21[0][0]']\n","                                                                                                  \n"," dense_31 (Dense)               (None, 3136)         9408        ['lambda_7[0][0]']               \n","                                                                                                  \n"," reshape_7 (Reshape)            (None, 1, 49, 64)    0           ['dense_31[0][0]']               \n","                                                                                                  \n"," conv2d_transpose_21 (Conv2DTra  (None, 22, 49, 64)  90176       ['reshape_7[0][0]']              \n"," nspose)                                                                                          \n","                                                                                                  \n"," leaky_re_lu_30 (LeakyReLU)     (None, 22, 49, 64)   0           ['conv2d_transpose_21[0][0]']    \n","                                                                                                  \n"," conv2d_transpose_22 (Conv2DTra  (None, 22, 1000, 32  81952      ['leaky_re_lu_30[0][0]']         \n"," nspose)                        )                                                                 \n","                                                                                                  \n"," leaky_re_lu_31 (LeakyReLU)     (None, 22, 1000, 32  0           ['conv2d_transpose_22[0][0]']    \n","                                )                                                                 \n","                                                                                                  \n"," conv2d_transpose_23 (Conv2DTra  (None, 22, 1000, 1)  801        ['leaky_re_lu_31[0][0]']         \n"," nspose)                                                                                          \n","                                                                                                  \n","==================================================================================================\n","Total params: 279,029\n","Trainable params: 279,029\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n","Epoch 1/30\n","34/34 [==============================] - 4s 94ms/step - loss: 2636077.5000 - val_loss: 2554359.7500\n","Epoch 2/30\n","34/34 [==============================] - 3s 86ms/step - loss: 2501660.5000 - val_loss: 2487916.0000\n","Epoch 3/30\n","34/34 [==============================] - 3s 89ms/step - loss: 2463856.0000 - val_loss: 2476774.7500\n","Epoch 4/30\n","34/34 [==============================] - 3s 86ms/step - loss: 2437902.0000 - val_loss: 2476489.7500\n","Epoch 5/30\n","34/34 [==============================] - 3s 86ms/step - loss: 2461250.7500 - val_loss: 2472126.0000\n","Epoch 6/30\n","34/34 [==============================] - 3s 86ms/step - loss: 2441934.0000 - val_loss: 2463257.2500\n","Epoch 7/30\n","34/34 [==============================] - 3s 86ms/step - loss: 2457462.7500 - val_loss: 2458854.0000\n","Epoch 8/30\n","34/34 [==============================] - 3s 85ms/step - loss: 2427964.2500 - val_loss: 2450008.2500\n","Epoch 9/30\n","34/34 [==============================] - 3s 88ms/step - loss: 2437084.7500 - val_loss: 2447192.5000\n","Epoch 10/30\n","34/34 [==============================] - 3s 86ms/step - loss: 2411345.7500 - val_loss: 2443148.2500\n","Epoch 11/30\n","34/34 [==============================] - 3s 86ms/step - loss: 2434616.7500 - val_loss: 2448610.7500\n","Epoch 12/30\n","34/34 [==============================] - 3s 87ms/step - loss: 2433173.0000 - val_loss: 2452032.2500\n","Epoch 13/30\n","34/34 [==============================] - 3s 88ms/step - loss: 2434390.0000 - val_loss: 2444552.5000\n","Epoch 14/30\n","34/34 [==============================] - 3s 85ms/step - loss: 2415987.7500 - val_loss: 2442142.7500\n","Epoch 15/30\n","34/34 [==============================] - 3s 90ms/step - loss: 2420047.7500 - val_loss: 2433223.2500\n","Epoch 16/30\n","34/34 [==============================] - 3s 87ms/step - loss: 2452990.0000 - val_loss: 2436178.2500\n","Epoch 17/30\n","34/34 [==============================] - 3s 85ms/step - loss: 2401731.7500 - val_loss: 2436637.5000\n","Epoch 18/30\n","34/34 [==============================] - 3s 89ms/step - loss: 2449551.5000 - val_loss: 2438652.5000\n","Epoch 19/30\n","34/34 [==============================] - 3s 87ms/step - loss: 2416413.2500 - val_loss: 2433034.7500\n","Epoch 20/30\n","34/34 [==============================] - 3s 89ms/step - loss: 2411645.0000 - val_loss: 2432572.7500\n","Epoch 21/30\n","34/34 [==============================] - 3s 89ms/step - loss: 2408867.5000 - val_loss: 2436275.7500\n","Epoch 22/30\n","34/34 [==============================] - 3s 86ms/step - loss: 2400789.2500 - val_loss: 2431283.2500\n","Epoch 23/30\n","34/34 [==============================] - 3s 89ms/step - loss: 2390582.2500 - val_loss: 2433789.7500\n","Epoch 24/30\n","34/34 [==============================] - 3s 87ms/step - loss: 2398580.7500 - val_loss: 2434973.5000\n","Epoch 25/30\n","34/34 [==============================] - 3s 86ms/step - loss: 2398486.0000 - val_loss: 2434175.5000\n","Epoch 26/30\n","34/34 [==============================] - 3s 89ms/step - loss: 2388434.7500 - val_loss: 2432235.5000\n","Epoch 27/30\n","34/34 [==============================] - 3s 86ms/step - loss: 2423280.7500 - val_loss: 2452856.0000\n","Epoch 28/30\n","34/34 [==============================] - 3s 86ms/step - loss: 2432839.0000 - val_loss: 2447572.5000\n","Epoch 29/30\n","34/34 [==============================] - 3s 86ms/step - loss: 2415906.7500 - val_loss: 2448101.7500\n","Epoch 30/30\n","34/34 [==============================] - 3s 86ms/step - loss: 2394853.2500 - val_loss: 2461798.7500\n","Model: \"vae\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," input_9 (InputLayer)           [(None, 22, 1000, 1  0           []                               \n","                                )]                                                                \n","                                                                                                  \n"," conv2d_16 (Conv2D)             (None, 22, 49, 32)   1312        ['input_9[0][0]']                \n","                                                                                                  \n"," leaky_re_lu_32 (LeakyReLU)     (None, 22, 49, 32)   0           ['conv2d_16[0][0]']              \n","                                                                                                  \n"," conv2d_17 (Conv2D)             (None, 1, 49, 64)    45120       ['leaky_re_lu_32[0][0]']         \n","                                                                                                  \n"," leaky_re_lu_33 (LeakyReLU)     (None, 1, 49, 64)    0           ['conv2d_17[0][0]']              \n","                                                                                                  \n"," flatten_8 (Flatten)            (None, 3136)         0           ['leaky_re_lu_33[0][0]']         \n","                                                                                                  \n"," dense_32 (Dense)               (None, 16)           50192       ['flatten_8[0][0]']              \n","                                                                                                  \n"," dense_34 (Dense)               (None, 2)            34          ['dense_32[0][0]']               \n","                                                                                                  \n"," dense_33 (Dense)               (None, 2)            34          ['dense_32[0][0]']               \n","                                                                                                  \n"," tf.__operators__.add_24 (TFOpL  (None, 2)           0           ['dense_34[0][0]']               \n"," ambda)                                                                                           \n","                                                                                                  \n"," lambda_8 (Lambda)              (None, 2)            0           ['dense_33[0][0]',               \n","                                                                  'tf.__operators__.add_24[0][0]']\n","                                                                                                  \n"," dense_35 (Dense)               (None, 3136)         9408        ['lambda_8[0][0]']               \n","                                                                                                  \n"," reshape_8 (Reshape)            (None, 1, 49, 64)    0           ['dense_35[0][0]']               \n","                                                                                                  \n"," conv2d_transpose_24 (Conv2DTra  (None, 22, 49, 64)  90176       ['reshape_8[0][0]']              \n"," nspose)                                                                                          \n","                                                                                                  \n"," leaky_re_lu_34 (LeakyReLU)     (None, 22, 49, 64)   0           ['conv2d_transpose_24[0][0]']    \n","                                                                                                  \n"," conv2d_transpose_25 (Conv2DTra  (None, 22, 1000, 32  81952      ['leaky_re_lu_34[0][0]']         \n"," nspose)                        )                                                                 \n","                                                                                                  \n"," leaky_re_lu_35 (LeakyReLU)     (None, 22, 1000, 32  0           ['conv2d_transpose_25[0][0]']    \n","                                )                                                                 \n","                                                                                                  \n"," conv2d_transpose_26 (Conv2DTra  (None, 22, 1000, 1)  801        ['leaky_re_lu_35[0][0]']         \n"," nspose)                                                                                          \n","                                                                                                  \n","==================================================================================================\n","Total params: 279,029\n","Trainable params: 279,029\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n","Epoch 1/30\n","17/17 [==============================] - 5s 265ms/step - loss: 2571450.0000 - val_loss: 2749853.5000\n","Epoch 2/30\n","17/17 [==============================] - 3s 161ms/step - loss: 2529879.7500 - val_loss: 2662059.0000\n","Epoch 3/30\n","17/17 [==============================] - 3s 161ms/step - loss: 2457147.7500 - val_loss: 2622478.7500\n","Epoch 4/30\n","17/17 [==============================] - 3s 161ms/step - loss: 2427998.2500 - val_loss: 2607675.0000\n","Epoch 5/30\n","17/17 [==============================] - 3s 166ms/step - loss: 2421794.0000 - val_loss: 2612532.0000\n","Epoch 6/30\n","17/17 [==============================] - 3s 170ms/step - loss: 2418554.5000 - val_loss: 2598819.0000\n","Epoch 7/30\n","17/17 [==============================] - 3s 161ms/step - loss: 2418921.0000 - val_loss: 2604997.7500\n","Epoch 8/30\n","17/17 [==============================] - 3s 162ms/step - loss: 2416206.2500 - val_loss: 2597295.0000\n","Epoch 9/30\n","17/17 [==============================] - 3s 162ms/step - loss: 2414226.7500 - val_loss: 2596884.0000\n","Epoch 10/30\n","17/17 [==============================] - 3s 168ms/step - loss: 2410037.2500 - val_loss: 2597373.2500\n","Epoch 11/30\n","17/17 [==============================] - 3s 167ms/step - loss: 2410564.5000 - val_loss: 2597156.5000\n","Epoch 12/30\n","17/17 [==============================] - 3s 162ms/step - loss: 2404770.5000 - val_loss: 2595711.0000\n","Epoch 13/30\n","17/17 [==============================] - 3s 161ms/step - loss: 2403905.2500 - val_loss: 2602062.0000\n","Epoch 14/30\n","17/17 [==============================] - 3s 163ms/step - loss: 2407281.0000 - val_loss: 2595674.5000\n","Epoch 15/30\n","17/17 [==============================] - 3s 162ms/step - loss: 2408768.5000 - val_loss: 2607946.5000\n","Epoch 16/30\n","17/17 [==============================] - 3s 160ms/step - loss: 2401578.0000 - val_loss: 2594753.2500\n","Epoch 17/30\n","17/17 [==============================] - 3s 168ms/step - loss: 2405285.7500 - val_loss: 2608665.5000\n","Epoch 18/30\n","17/17 [==============================] - 3s 162ms/step - loss: 2403477.5000 - val_loss: 2602522.2500\n","Epoch 19/30\n","17/17 [==============================] - 3s 162ms/step - loss: 2395119.5000 - val_loss: 2594755.2500\n","Epoch 20/30\n","17/17 [==============================] - 3s 167ms/step - loss: 2394345.0000 - val_loss: 2595939.7500\n","Epoch 21/30\n","17/17 [==============================] - 3s 162ms/step - loss: 2394246.0000 - val_loss: 2598275.2500\n","Epoch 22/30\n","17/17 [==============================] - 3s 170ms/step - loss: 2397579.7500 - val_loss: 2606247.2500\n","Epoch 23/30\n","17/17 [==============================] - 3s 162ms/step - loss: 2405459.7500 - val_loss: 2594575.0000\n","Epoch 24/30\n","17/17 [==============================] - 3s 164ms/step - loss: 2392150.0000 - val_loss: 2594978.7500\n","Epoch 25/30\n","17/17 [==============================] - 3s 168ms/step - loss: 2397504.5000 - val_loss: 2606027.2500\n","Epoch 26/30\n","17/17 [==============================] - 3s 162ms/step - loss: 2392332.0000 - val_loss: 2600942.0000\n","Epoch 27/30\n","17/17 [==============================] - 3s 168ms/step - loss: 2395034.0000 - val_loss: 2601689.7500\n","Epoch 28/30\n","17/17 [==============================] - 3s 161ms/step - loss: 2395948.7500 - val_loss: 2600412.7500\n","Epoch 29/30\n","17/17 [==============================] - 3s 161ms/step - loss: 2392351.2500 - val_loss: 2597123.0000\n","Epoch 30/30\n","17/17 [==============================] - 3s 163ms/step - loss: 2385923.0000 - val_loss: 2599022.5000\n","Model: \"vae\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," input_10 (InputLayer)          [(None, 22, 1000, 1  0           []                               \n","                                )]                                                                \n","                                                                                                  \n"," conv2d_18 (Conv2D)             (None, 22, 49, 32)   1312        ['input_10[0][0]']               \n","                                                                                                  \n"," leaky_re_lu_36 (LeakyReLU)     (None, 22, 49, 32)   0           ['conv2d_18[0][0]']              \n","                                                                                                  \n"," conv2d_19 (Conv2D)             (None, 1, 49, 64)    45120       ['leaky_re_lu_36[0][0]']         \n","                                                                                                  \n"," leaky_re_lu_37 (LeakyReLU)     (None, 1, 49, 64)    0           ['conv2d_19[0][0]']              \n","                                                                                                  \n"," flatten_9 (Flatten)            (None, 3136)         0           ['leaky_re_lu_37[0][0]']         \n","                                                                                                  \n"," dense_36 (Dense)               (None, 16)           50192       ['flatten_9[0][0]']              \n","                                                                                                  \n"," dense_38 (Dense)               (None, 2)            34          ['dense_36[0][0]']               \n","                                                                                                  \n"," dense_37 (Dense)               (None, 2)            34          ['dense_36[0][0]']               \n","                                                                                                  \n"," tf.__operators__.add_27 (TFOpL  (None, 2)           0           ['dense_38[0][0]']               \n"," ambda)                                                                                           \n","                                                                                                  \n"," lambda_9 (Lambda)              (None, 2)            0           ['dense_37[0][0]',               \n","                                                                  'tf.__operators__.add_27[0][0]']\n","                                                                                                  \n"," dense_39 (Dense)               (None, 3136)         9408        ['lambda_9[0][0]']               \n","                                                                                                  \n"," reshape_9 (Reshape)            (None, 1, 49, 64)    0           ['dense_39[0][0]']               \n","                                                                                                  \n"," conv2d_transpose_27 (Conv2DTra  (None, 22, 49, 64)  90176       ['reshape_9[0][0]']              \n"," nspose)                                                                                          \n","                                                                                                  \n"," leaky_re_lu_38 (LeakyReLU)     (None, 22, 49, 64)   0           ['conv2d_transpose_27[0][0]']    \n","                                                                                                  \n"," conv2d_transpose_28 (Conv2DTra  (None, 22, 1000, 32  81952      ['leaky_re_lu_38[0][0]']         \n"," nspose)                        )                                                                 \n","                                                                                                  \n"," leaky_re_lu_39 (LeakyReLU)     (None, 22, 1000, 32  0           ['conv2d_transpose_28[0][0]']    \n","                                )                                                                 \n","                                                                                                  \n"," conv2d_transpose_29 (Conv2DTra  (None, 22, 1000, 1)  801        ['leaky_re_lu_39[0][0]']         \n"," nspose)                                                                                          \n","                                                                                                  \n","==================================================================================================\n","Total params: 279,029\n","Trainable params: 279,029\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n","Epoch 1/30\n","67/67 [==============================] - 4s 51ms/step - loss: 2656616.0000 - val_loss: 2587173.7500\n","Epoch 2/30\n","67/67 [==============================] - 3s 48ms/step - loss: 2585567.2500 - val_loss: 2586326.0000\n","Epoch 3/30\n","67/67 [==============================] - 3s 49ms/step - loss: 2568688.2500 - val_loss: 2585124.2500\n","Epoch 4/30\n","67/67 [==============================] - 3s 48ms/step - loss: 2575396.7500 - val_loss: 2581397.7500\n","Epoch 5/30\n","67/67 [==============================] - 3s 48ms/step - loss: 2563557.7500 - val_loss: 2582425.2500\n","Epoch 6/30\n","67/67 [==============================] - 3s 49ms/step - loss: 2566588.0000 - val_loss: 2576833.7500\n","Epoch 7/30\n","67/67 [==============================] - 3s 47ms/step - loss: 2558715.0000 - val_loss: 2557090.7500\n","Epoch 8/30\n","67/67 [==============================] - 3s 49ms/step - loss: 2493292.0000 - val_loss: 2497796.2500\n","Epoch 9/30\n","67/67 [==============================] - 3s 49ms/step - loss: 2477439.2500 - val_loss: 2481913.5000\n","Epoch 10/30\n","67/67 [==============================] - 3s 48ms/step - loss: 2451851.7500 - val_loss: 2474610.2500\n","Epoch 11/30\n","67/67 [==============================] - 3s 48ms/step - loss: 2451295.5000 - val_loss: 2471708.7500\n","Epoch 12/30\n","67/67 [==============================] - 3s 47ms/step - loss: 2456707.0000 - val_loss: 2470032.7500\n","Epoch 13/30\n","67/67 [==============================] - 3s 47ms/step - loss: 2448540.5000 - val_loss: 2471668.5000\n","Epoch 14/30\n","67/67 [==============================] - 3s 48ms/step - loss: 2442402.0000 - val_loss: 2467048.5000\n","Epoch 15/30\n","67/67 [==============================] - 3s 48ms/step - loss: 2438770.7500 - val_loss: 2463126.7500\n","Epoch 16/30\n","67/67 [==============================] - 3s 47ms/step - loss: 2432778.7500 - val_loss: 2457793.5000\n","Epoch 17/30\n","67/67 [==============================] - 3s 48ms/step - loss: 2430275.2500 - val_loss: 2449853.5000\n","Epoch 18/30\n","67/67 [==============================] - 3s 47ms/step - loss: 2433434.7500 - val_loss: 2445313.7500\n","Epoch 19/30\n","67/67 [==============================] - 3s 48ms/step - loss: 2432741.0000 - val_loss: 2443771.2500\n","Epoch 20/30\n","67/67 [==============================] - 3s 48ms/step - loss: 2426769.2500 - val_loss: 2442284.2500\n","Epoch 21/30\n","67/67 [==============================] - 3s 48ms/step - loss: 2413520.0000 - val_loss: 2442670.7500\n","Epoch 22/30\n","67/67 [==============================] - 3s 47ms/step - loss: 2436387.2500 - val_loss: 2441792.5000\n","Epoch 23/30\n","67/67 [==============================] - 3s 48ms/step - loss: 2423774.0000 - val_loss: 2441545.7500\n","Epoch 24/30\n","67/67 [==============================] - 3s 49ms/step - loss: 2443219.7500 - val_loss: 2438608.2500\n","Epoch 25/30\n","67/67 [==============================] - 3s 47ms/step - loss: 2405455.7500 - val_loss: 2435473.2500\n","Epoch 26/30\n","67/67 [==============================] - 3s 47ms/step - loss: 2403651.0000 - val_loss: 2436041.7500\n","Epoch 27/30\n","67/67 [==============================] - 3s 48ms/step - loss: 2406691.0000 - val_loss: 2435888.5000\n","Epoch 28/30\n","67/67 [==============================] - 3s 48ms/step - loss: 2402067.2500 - val_loss: 2435838.2500\n","Epoch 29/30\n","67/67 [==============================] - 3s 48ms/step - loss: 2400260.0000 - val_loss: 2433306.5000\n","Epoch 30/30\n","67/67 [==============================] - 3s 49ms/step - loss: 2411021.2500 - val_loss: 2434162.5000\n","Model: \"vae\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," input_11 (InputLayer)          [(None, 22, 1000, 1  0           []                               \n","                                )]                                                                \n","                                                                                                  \n"," conv2d_20 (Conv2D)             (None, 22, 49, 32)   1312        ['input_11[0][0]']               \n","                                                                                                  \n"," leaky_re_lu_40 (LeakyReLU)     (None, 22, 49, 32)   0           ['conv2d_20[0][0]']              \n","                                                                                                  \n"," conv2d_21 (Conv2D)             (None, 1, 49, 64)    45120       ['leaky_re_lu_40[0][0]']         \n","                                                                                                  \n"," leaky_re_lu_41 (LeakyReLU)     (None, 1, 49, 64)    0           ['conv2d_21[0][0]']              \n","                                                                                                  \n"," flatten_10 (Flatten)           (None, 3136)         0           ['leaky_re_lu_41[0][0]']         \n","                                                                                                  \n"," dense_40 (Dense)               (None, 16)           50192       ['flatten_10[0][0]']             \n","                                                                                                  \n"," dense_42 (Dense)               (None, 2)            34          ['dense_40[0][0]']               \n","                                                                                                  \n"," dense_41 (Dense)               (None, 2)            34          ['dense_40[0][0]']               \n","                                                                                                  \n"," tf.__operators__.add_30 (TFOpL  (None, 2)           0           ['dense_42[0][0]']               \n"," ambda)                                                                                           \n","                                                                                                  \n"," lambda_10 (Lambda)             (None, 2)            0           ['dense_41[0][0]',               \n","                                                                  'tf.__operators__.add_30[0][0]']\n","                                                                                                  \n"," dense_43 (Dense)               (None, 3136)         9408        ['lambda_10[0][0]']              \n","                                                                                                  \n"," reshape_10 (Reshape)           (None, 1, 49, 64)    0           ['dense_43[0][0]']               \n","                                                                                                  \n"," conv2d_transpose_30 (Conv2DTra  (None, 22, 49, 64)  90176       ['reshape_10[0][0]']             \n"," nspose)                                                                                          \n","                                                                                                  \n"," leaky_re_lu_42 (LeakyReLU)     (None, 22, 49, 64)   0           ['conv2d_transpose_30[0][0]']    \n","                                                                                                  \n"," conv2d_transpose_31 (Conv2DTra  (None, 22, 1000, 32  81952      ['leaky_re_lu_42[0][0]']         \n"," nspose)                        )                                                                 \n","                                                                                                  \n"," leaky_re_lu_43 (LeakyReLU)     (None, 22, 1000, 32  0           ['conv2d_transpose_31[0][0]']    \n","                                )                                                                 \n","                                                                                                  \n"," conv2d_transpose_32 (Conv2DTra  (None, 22, 1000, 1)  801        ['leaky_re_lu_43[0][0]']         \n"," nspose)                                                                                          \n","                                                                                                  \n","==================================================================================================\n","Total params: 279,029\n","Trainable params: 279,029\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n","Epoch 1/30\n","34/34 [==============================] - 4s 96ms/step - loss: 2575620.7500 - val_loss: 2576181.7500\n","Epoch 2/30\n","34/34 [==============================] - 3s 87ms/step - loss: 2502195.5000 - val_loss: 2486171.2500\n","Epoch 3/30\n","34/34 [==============================] - 3s 87ms/step - loss: 2442136.7500 - val_loss: 2451001.7500\n","Epoch 4/30\n","34/34 [==============================] - 3s 89ms/step - loss: 2415339.5000 - val_loss: 2443837.2500\n","Epoch 5/30\n","34/34 [==============================] - 3s 89ms/step - loss: 2438711.0000 - val_loss: 2443462.5000\n","Epoch 6/30\n","34/34 [==============================] - 3s 87ms/step - loss: 2458909.5000 - val_loss: 2440254.7500\n","Epoch 7/30\n","34/34 [==============================] - 3s 91ms/step - loss: 2415217.0000 - val_loss: 2450017.7500\n","Epoch 8/30\n","34/34 [==============================] - 3s 86ms/step - loss: 2387417.7500 - val_loss: 2436282.7500\n","Epoch 9/30\n","34/34 [==============================] - 3s 87ms/step - loss: 2435856.2500 - val_loss: 2438254.0000\n","Epoch 10/30\n","34/34 [==============================] - 3s 91ms/step - loss: 2427145.2500 - val_loss: 2439296.2500\n","Epoch 11/30\n","34/34 [==============================] - 3s 89ms/step - loss: 2398561.5000 - val_loss: 2435343.5000\n","Epoch 12/30\n","34/34 [==============================] - 3s 89ms/step - loss: 2396465.7500 - val_loss: 2433574.0000\n","Epoch 13/30\n","34/34 [==============================] - 3s 87ms/step - loss: 2393858.5000 - val_loss: 2432508.7500\n","Epoch 14/30\n","34/34 [==============================] - 3s 88ms/step - loss: 2395113.0000 - val_loss: 2434398.5000\n","Epoch 15/30\n","34/34 [==============================] - 3s 87ms/step - loss: 2412134.7500 - val_loss: 2433718.0000\n","Epoch 16/30\n","34/34 [==============================] - 3s 90ms/step - loss: 2408576.2500 - val_loss: 2440642.7500\n","Epoch 17/30\n","34/34 [==============================] - 3s 86ms/step - loss: 2433282.7500 - val_loss: 2433549.7500\n","Epoch 18/30\n","34/34 [==============================] - 3s 89ms/step - loss: 2414686.0000 - val_loss: 2439286.2500\n","Epoch 19/30\n","34/34 [==============================] - 3s 87ms/step - loss: 2395424.2500 - val_loss: 2436213.7500\n","Epoch 20/30\n","34/34 [==============================] - 3s 90ms/step - loss: 2379094.5000 - val_loss: 2431479.2500\n","Epoch 21/30\n","34/34 [==============================] - 3s 89ms/step - loss: 2392355.0000 - val_loss: 2444112.2500\n","Epoch 22/30\n","34/34 [==============================] - 3s 87ms/step - loss: 2407118.2500 - val_loss: 2489626.2500\n","Epoch 23/30\n","34/34 [==============================] - 3s 86ms/step - loss: 2408598.2500 - val_loss: 2435060.5000\n","Epoch 24/30\n","34/34 [==============================] - 3s 87ms/step - loss: 2420178.0000 - val_loss: 2434600.2500\n","Epoch 25/30\n","34/34 [==============================] - 3s 90ms/step - loss: 2397817.2500 - val_loss: 2443004.5000\n","Epoch 26/30\n","34/34 [==============================] - 3s 87ms/step - loss: 2374550.0000 - val_loss: 2440942.5000\n","Epoch 27/30\n","34/34 [==============================] - 3s 88ms/step - loss: 2382936.0000 - val_loss: 2432605.7500\n","Epoch 28/30\n","34/34 [==============================] - 3s 87ms/step - loss: 2378771.7500 - val_loss: 2435104.5000\n","Epoch 29/30\n","34/34 [==============================] - 3s 90ms/step - loss: 2397135.0000 - val_loss: 2434624.5000\n","Epoch 30/30\n","34/34 [==============================] - 3s 89ms/step - loss: 2407548.7500 - val_loss: 2439210.5000\n","Model: \"vae\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," input_12 (InputLayer)          [(None, 22, 1000, 1  0           []                               \n","                                )]                                                                \n","                                                                                                  \n"," conv2d_22 (Conv2D)             (None, 22, 49, 32)   1312        ['input_12[0][0]']               \n","                                                                                                  \n"," leaky_re_lu_44 (LeakyReLU)     (None, 22, 49, 32)   0           ['conv2d_22[0][0]']              \n","                                                                                                  \n"," conv2d_23 (Conv2D)             (None, 1, 49, 64)    45120       ['leaky_re_lu_44[0][0]']         \n","                                                                                                  \n"," leaky_re_lu_45 (LeakyReLU)     (None, 1, 49, 64)    0           ['conv2d_23[0][0]']              \n","                                                                                                  \n"," flatten_11 (Flatten)           (None, 3136)         0           ['leaky_re_lu_45[0][0]']         \n","                                                                                                  \n"," dense_44 (Dense)               (None, 16)           50192       ['flatten_11[0][0]']             \n","                                                                                                  \n"," dense_46 (Dense)               (None, 2)            34          ['dense_44[0][0]']               \n","                                                                                                  \n"," dense_45 (Dense)               (None, 2)            34          ['dense_44[0][0]']               \n","                                                                                                  \n"," tf.__operators__.add_33 (TFOpL  (None, 2)           0           ['dense_46[0][0]']               \n"," ambda)                                                                                           \n","                                                                                                  \n"," lambda_11 (Lambda)             (None, 2)            0           ['dense_45[0][0]',               \n","                                                                  'tf.__operators__.add_33[0][0]']\n","                                                                                                  \n"," dense_47 (Dense)               (None, 3136)         9408        ['lambda_11[0][0]']              \n","                                                                                                  \n"," reshape_11 (Reshape)           (None, 1, 49, 64)    0           ['dense_47[0][0]']               \n","                                                                                                  \n"," conv2d_transpose_33 (Conv2DTra  (None, 22, 49, 64)  90176       ['reshape_11[0][0]']             \n"," nspose)                                                                                          \n","                                                                                                  \n"," leaky_re_lu_46 (LeakyReLU)     (None, 22, 49, 64)   0           ['conv2d_transpose_33[0][0]']    \n","                                                                                                  \n"," conv2d_transpose_34 (Conv2DTra  (None, 22, 1000, 32  81952      ['leaky_re_lu_46[0][0]']         \n"," nspose)                        )                                                                 \n","                                                                                                  \n"," leaky_re_lu_47 (LeakyReLU)     (None, 22, 1000, 32  0           ['conv2d_transpose_34[0][0]']    \n","                                )                                                                 \n","                                                                                                  \n"," conv2d_transpose_35 (Conv2DTra  (None, 22, 1000, 1)  801        ['leaky_re_lu_47[0][0]']         \n"," nspose)                                                                                          \n","                                                                                                  \n","==================================================================================================\n","Total params: 279,029\n","Trainable params: 279,029\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n","Epoch 1/30\n","17/17 [==============================] - 4s 181ms/step - loss: 2566404.2500 - val_loss: 2738770.2500\n","Epoch 2/30\n","17/17 [==============================] - 3s 166ms/step - loss: 2516635.5000 - val_loss: 2677078.2500\n","Epoch 3/30\n","17/17 [==============================] - 3s 163ms/step - loss: 2452023.5000 - val_loss: 2620724.2500\n","Epoch 4/30\n","17/17 [==============================] - 3s 168ms/step - loss: 2427228.5000 - val_loss: 2609168.5000\n","Epoch 5/30\n","17/17 [==============================] - 3s 168ms/step - loss: 2428572.5000 - val_loss: 2607608.2500\n","Epoch 6/30\n","17/17 [==============================] - 3s 169ms/step - loss: 2417018.0000 - val_loss: 2606558.7500\n","Epoch 7/30\n","17/17 [==============================] - 3s 162ms/step - loss: 2418641.0000 - val_loss: 2600886.0000\n","Epoch 8/30\n","17/17 [==============================] - 3s 163ms/step - loss: 2410488.2500 - val_loss: 2602456.5000\n","Epoch 9/30\n","17/17 [==============================] - 3s 170ms/step - loss: 2406814.0000 - val_loss: 2597380.0000\n","Epoch 10/30\n","17/17 [==============================] - 3s 162ms/step - loss: 2408434.2500 - val_loss: 2597747.2500\n","Epoch 11/30\n","17/17 [==============================] - 3s 166ms/step - loss: 2413742.7500 - val_loss: 2602719.5000\n","Epoch 12/30\n","17/17 [==============================] - 3s 162ms/step - loss: 2419850.2500 - val_loss: 2596343.2500\n","Epoch 13/30\n","17/17 [==============================] - 3s 169ms/step - loss: 2409170.0000 - val_loss: 2594190.5000\n","Epoch 14/30\n","17/17 [==============================] - 3s 163ms/step - loss: 2404790.2500 - val_loss: 2594792.5000\n","Epoch 15/30\n","17/17 [==============================] - 3s 168ms/step - loss: 2404657.0000 - val_loss: 2598118.5000\n","Epoch 16/30\n","17/17 [==============================] - 3s 162ms/step - loss: 2413132.5000 - val_loss: 2593859.0000\n","Epoch 17/30\n","17/17 [==============================] - 3s 162ms/step - loss: 2402620.2500 - val_loss: 2594649.2500\n","Epoch 18/30\n","17/17 [==============================] - 3s 163ms/step - loss: 2402323.2500 - val_loss: 2594201.7500\n","Epoch 19/30\n","17/17 [==============================] - 3s 162ms/step - loss: 2402665.5000 - val_loss: 2593905.0000\n","Epoch 20/30\n","17/17 [==============================] - 3s 167ms/step - loss: 2404501.7500 - val_loss: 2593930.7500\n","Epoch 21/30\n","17/17 [==============================] - 3s 161ms/step - loss: 2409178.7500 - val_loss: 2593283.0000\n","Epoch 22/30\n","17/17 [==============================] - 3s 168ms/step - loss: 2403282.5000 - val_loss: 2592879.0000\n","Epoch 23/30\n","17/17 [==============================] - 3s 161ms/step - loss: 2397663.2500 - val_loss: 2593231.5000\n","Epoch 24/30\n","17/17 [==============================] - 3s 162ms/step - loss: 2397668.2500 - val_loss: 2592140.0000\n","Epoch 25/30\n","17/17 [==============================] - 3s 169ms/step - loss: 2397878.0000 - val_loss: 2592988.2500\n","Epoch 26/30\n","17/17 [==============================] - 3s 170ms/step - loss: 2396755.7500 - val_loss: 2592572.5000\n","Epoch 27/30\n","17/17 [==============================] - 3s 162ms/step - loss: 2391978.7500 - val_loss: 2596756.5000\n","Epoch 28/30\n","17/17 [==============================] - 3s 161ms/step - loss: 2400414.0000 - val_loss: 2593617.2500\n","Epoch 29/30\n","17/17 [==============================] - 3s 162ms/step - loss: 2399250.5000 - val_loss: 2592248.5000\n","Epoch 30/30\n","17/17 [==============================] - 3s 162ms/step - loss: 2400595.5000 - val_loss: 2594335.5000\n","Model: \"vae\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," input_13 (InputLayer)          [(None, 22, 1000, 1  0           []                               \n","                                )]                                                                \n","                                                                                                  \n"," conv2d_24 (Conv2D)             (None, 22, 49, 32)   1312        ['input_13[0][0]']               \n","                                                                                                  \n"," leaky_re_lu_48 (LeakyReLU)     (None, 22, 49, 32)   0           ['conv2d_24[0][0]']              \n","                                                                                                  \n"," conv2d_25 (Conv2D)             (None, 1, 49, 64)    45120       ['leaky_re_lu_48[0][0]']         \n","                                                                                                  \n"," leaky_re_lu_49 (LeakyReLU)     (None, 1, 49, 64)    0           ['conv2d_25[0][0]']              \n","                                                                                                  \n"," flatten_12 (Flatten)           (None, 3136)         0           ['leaky_re_lu_49[0][0]']         \n","                                                                                                  \n"," dense_48 (Dense)               (None, 16)           50192       ['flatten_12[0][0]']             \n","                                                                                                  \n"," dense_50 (Dense)               (None, 2)            34          ['dense_48[0][0]']               \n","                                                                                                  \n"," dense_49 (Dense)               (None, 2)            34          ['dense_48[0][0]']               \n","                                                                                                  \n"," tf.__operators__.add_36 (TFOpL  (None, 2)           0           ['dense_50[0][0]']               \n"," ambda)                                                                                           \n","                                                                                                  \n"," lambda_12 (Lambda)             (None, 2)            0           ['dense_49[0][0]',               \n","                                                                  'tf.__operators__.add_36[0][0]']\n","                                                                                                  \n"," dense_51 (Dense)               (None, 3136)         9408        ['lambda_12[0][0]']              \n","                                                                                                  \n"," reshape_12 (Reshape)           (None, 1, 49, 64)    0           ['dense_51[0][0]']               \n","                                                                                                  \n"," conv2d_transpose_36 (Conv2DTra  (None, 22, 49, 64)  90176       ['reshape_12[0][0]']             \n"," nspose)                                                                                          \n","                                                                                                  \n"," leaky_re_lu_50 (LeakyReLU)     (None, 22, 49, 64)   0           ['conv2d_transpose_36[0][0]']    \n","                                                                                                  \n"," conv2d_transpose_37 (Conv2DTra  (None, 22, 1000, 32  81952      ['leaky_re_lu_50[0][0]']         \n"," nspose)                        )                                                                 \n","                                                                                                  \n"," leaky_re_lu_51 (LeakyReLU)     (None, 22, 1000, 32  0           ['conv2d_transpose_37[0][0]']    \n","                                )                                                                 \n","                                                                                                  \n"," conv2d_transpose_38 (Conv2DTra  (None, 22, 1000, 1)  801        ['leaky_re_lu_51[0][0]']         \n"," nspose)                                                                                          \n","                                                                                                  \n","==================================================================================================\n","Total params: 279,029\n","Trainable params: 279,029\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n","Epoch 1/30\n","67/67 [==============================] - 5s 53ms/step - loss: 2806965.7500 - val_loss: 2495780.7500\n","Epoch 2/30\n","67/67 [==============================] - 3s 49ms/step - loss: 2445365.0000 - val_loss: 2457687.5000\n","Epoch 3/30\n","67/67 [==============================] - 3s 48ms/step - loss: 4122345.5000 - val_loss: 2585280.5000\n","Epoch 4/30\n","67/67 [==============================] - 3s 48ms/step - loss: 2592729.5000 - val_loss: 2582582.2500\n","Epoch 5/30\n","67/67 [==============================] - 3s 48ms/step - loss: 2557224.0000 - val_loss: 2579874.5000\n","Epoch 6/30\n","67/67 [==============================] - 3s 49ms/step - loss: 2572237.2500 - val_loss: 2575847.2500\n","Epoch 7/30\n","67/67 [==============================] - 3s 47ms/step - loss: 2551039.2500 - val_loss: 2568017.2500\n","Epoch 8/30\n","67/67 [==============================] - 3s 48ms/step - loss: 2545899.0000 - val_loss: 2552310.7500\n","Epoch 9/30\n","67/67 [==============================] - 3s 48ms/step - loss: 2525657.2500 - val_loss: 2533316.7500\n","Epoch 10/30\n","67/67 [==============================] - 3s 48ms/step - loss: 2514980.7500 - val_loss: 2521610.0000\n","Epoch 11/30\n","67/67 [==============================] - 3s 48ms/step - loss: 2494151.0000 - val_loss: 2511059.7500\n","Epoch 12/30\n","67/67 [==============================] - 3s 48ms/step - loss: 2485739.5000 - val_loss: 2503911.7500\n","Epoch 13/30\n","67/67 [==============================] - 3s 48ms/step - loss: 2490668.2500 - val_loss: 2500342.7500\n","Epoch 14/30\n","67/67 [==============================] - 3s 47ms/step - loss: 2514228.5000 - val_loss: 2498076.5000\n","Epoch 15/30\n","67/67 [==============================] - 3s 48ms/step - loss: 2473408.7500 - val_loss: 2495174.2500\n","Epoch 16/30\n","67/67 [==============================] - 3s 49ms/step - loss: 2475509.7500 - val_loss: 2493142.0000\n","Epoch 17/30\n","67/67 [==============================] - 3s 49ms/step - loss: 2462745.7500 - val_loss: 2490544.7500\n","Epoch 18/30\n","67/67 [==============================] - 3s 49ms/step - loss: 2485869.0000 - val_loss: 2487954.5000\n","Epoch 19/30\n","67/67 [==============================] - 3s 49ms/step - loss: 2471375.7500 - val_loss: 2484538.0000\n","Epoch 20/30\n","67/67 [==============================] - 3s 48ms/step - loss: 2472952.7500 - val_loss: 2479900.0000\n","Epoch 21/30\n","67/67 [==============================] - 3s 48ms/step - loss: 2475523.7500 - val_loss: 2475750.0000\n","Epoch 22/30\n","67/67 [==============================] - 3s 48ms/step - loss: 2454945.5000 - val_loss: 2471156.7500\n","Epoch 23/30\n","67/67 [==============================] - 3s 47ms/step - loss: 2447807.2500 - val_loss: 2467710.0000\n","Epoch 24/30\n","67/67 [==============================] - 3s 48ms/step - loss: 2443708.2500 - val_loss: 2465430.7500\n","Epoch 25/30\n","67/67 [==============================] - 3s 49ms/step - loss: 2430326.5000 - val_loss: 2461706.0000\n","Epoch 26/30\n","67/67 [==============================] - 3s 49ms/step - loss: 2430533.2500 - val_loss: 2458432.5000\n","Epoch 27/30\n","67/67 [==============================] - 3s 48ms/step - loss: 2425560.5000 - val_loss: 2453330.2500\n","Epoch 28/30\n","67/67 [==============================] - 3s 48ms/step - loss: 2460505.5000 - val_loss: 2449197.5000\n","Epoch 29/30\n","67/67 [==============================] - 3s 48ms/step - loss: 2451342.2500 - val_loss: 2445371.7500\n","Epoch 30/30\n","67/67 [==============================] - 3s 47ms/step - loss: 2430911.2500 - val_loss: 2442640.0000\n","Model: \"vae\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," input_14 (InputLayer)          [(None, 22, 1000, 1  0           []                               \n","                                )]                                                                \n","                                                                                                  \n"," conv2d_26 (Conv2D)             (None, 22, 49, 32)   1312        ['input_14[0][0]']               \n","                                                                                                  \n"," leaky_re_lu_52 (LeakyReLU)     (None, 22, 49, 32)   0           ['conv2d_26[0][0]']              \n","                                                                                                  \n"," conv2d_27 (Conv2D)             (None, 1, 49, 64)    45120       ['leaky_re_lu_52[0][0]']         \n","                                                                                                  \n"," leaky_re_lu_53 (LeakyReLU)     (None, 1, 49, 64)    0           ['conv2d_27[0][0]']              \n","                                                                                                  \n"," flatten_13 (Flatten)           (None, 3136)         0           ['leaky_re_lu_53[0][0]']         \n","                                                                                                  \n"," dense_52 (Dense)               (None, 16)           50192       ['flatten_13[0][0]']             \n","                                                                                                  \n"," dense_54 (Dense)               (None, 2)            34          ['dense_52[0][0]']               \n","                                                                                                  \n"," dense_53 (Dense)               (None, 2)            34          ['dense_52[0][0]']               \n","                                                                                                  \n"," tf.__operators__.add_39 (TFOpL  (None, 2)           0           ['dense_54[0][0]']               \n"," ambda)                                                                                           \n","                                                                                                  \n"," lambda_13 (Lambda)             (None, 2)            0           ['dense_53[0][0]',               \n","                                                                  'tf.__operators__.add_39[0][0]']\n","                                                                                                  \n"," dense_55 (Dense)               (None, 3136)         9408        ['lambda_13[0][0]']              \n","                                                                                                  \n"," reshape_13 (Reshape)           (None, 1, 49, 64)    0           ['dense_55[0][0]']               \n","                                                                                                  \n"," conv2d_transpose_39 (Conv2DTra  (None, 22, 49, 64)  90176       ['reshape_13[0][0]']             \n"," nspose)                                                                                          \n","                                                                                                  \n"," leaky_re_lu_54 (LeakyReLU)     (None, 22, 49, 64)   0           ['conv2d_transpose_39[0][0]']    \n","                                                                                                  \n"," conv2d_transpose_40 (Conv2DTra  (None, 22, 1000, 32  81952      ['leaky_re_lu_54[0][0]']         \n"," nspose)                        )                                                                 \n","                                                                                                  \n"," leaky_re_lu_55 (LeakyReLU)     (None, 22, 1000, 32  0           ['conv2d_transpose_40[0][0]']    \n","                                )                                                                 \n","                                                                                                  \n"," conv2d_transpose_41 (Conv2DTra  (None, 22, 1000, 1)  801        ['leaky_re_lu_55[0][0]']         \n"," nspose)                                                                                          \n","                                                                                                  \n","==================================================================================================\n","Total params: 279,029\n","Trainable params: 279,029\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n","Epoch 1/30\n","34/34 [==============================] - 5s 95ms/step - loss: 41529140.0000 - val_loss: 2544910.5000\n","Epoch 2/30\n","34/34 [==============================] - 3s 87ms/step - loss: 2494784.2500 - val_loss: 2496630.2500\n","Epoch 3/30\n","34/34 [==============================] - 3s 88ms/step - loss: 2473102.7500 - val_loss: 2485680.2500\n","Epoch 4/30\n","34/34 [==============================] - 3s 88ms/step - loss: 2444077.2500 - val_loss: 2478284.5000\n","Epoch 5/30\n","34/34 [==============================] - 3s 86ms/step - loss: 2451411.2500 - val_loss: 2473438.2500\n","Epoch 6/30\n","34/34 [==============================] - 3s 88ms/step - loss: 2462285.0000 - val_loss: 2469899.5000\n","Epoch 7/30\n","34/34 [==============================] - 3s 87ms/step - loss: 2483944.5000 - val_loss: 2468645.7500\n","Epoch 8/30\n","34/34 [==============================] - 3s 87ms/step - loss: 2476236.2500 - val_loss: 2466339.2500\n","Epoch 9/30\n","34/34 [==============================] - 3s 90ms/step - loss: 2456829.5000 - val_loss: 2463539.5000\n","Epoch 10/30\n","34/34 [==============================] - 3s 88ms/step - loss: 2455674.2500 - val_loss: 2461228.2500\n","Epoch 11/30\n","34/34 [==============================] - 3s 87ms/step - loss: 2427244.2500 - val_loss: 2459586.7500\n","Epoch 12/30\n","34/34 [==============================] - 3s 90ms/step - loss: 2443895.7500 - val_loss: 2458196.2500\n","Epoch 13/30\n","34/34 [==============================] - 3s 86ms/step - loss: 2451885.5000 - val_loss: 2456342.0000\n","Epoch 14/30\n","34/34 [==============================] - 3s 90ms/step - loss: 2423688.7500 - val_loss: 2455558.2500\n","Epoch 15/30\n","34/34 [==============================] - 3s 87ms/step - loss: 2459305.7500 - val_loss: 2452524.7500\n","Epoch 16/30\n","34/34 [==============================] - 3s 89ms/step - loss: 2454493.5000 - val_loss: 2451379.2500\n","Epoch 17/30\n","34/34 [==============================] - 3s 87ms/step - loss: 2414633.7500 - val_loss: 2450741.7500\n","Epoch 18/30\n","34/34 [==============================] - 3s 87ms/step - loss: 2453823.2500 - val_loss: 2450857.5000\n","Epoch 19/30\n","34/34 [==============================] - 3s 89ms/step - loss: 2447379.5000 - val_loss: 2449356.5000\n","Epoch 20/30\n","34/34 [==============================] - 3s 87ms/step - loss: 2402446.5000 - val_loss: 2447868.5000\n","Epoch 21/30\n","34/34 [==============================] - 3s 86ms/step - loss: 2421010.2500 - val_loss: 2446352.5000\n","Epoch 22/30\n","34/34 [==============================] - 3s 89ms/step - loss: 2432255.0000 - val_loss: 2445948.2500\n","Epoch 23/30\n","34/34 [==============================] - 3s 87ms/step - loss: 2422226.0000 - val_loss: 2445714.7500\n","Epoch 24/30\n","34/34 [==============================] - 3s 87ms/step - loss: 2440911.0000 - val_loss: 2444683.5000\n","Epoch 25/30\n","34/34 [==============================] - 3s 87ms/step - loss: 2401022.5000 - val_loss: 2444149.5000\n","Epoch 26/30\n","34/34 [==============================] - 3s 87ms/step - loss: 2436282.7500 - val_loss: 2443928.7500\n","Epoch 27/30\n","34/34 [==============================] - 3s 91ms/step - loss: 2435062.5000 - val_loss: 2443098.7500\n","Epoch 28/30\n","34/34 [==============================] - 3s 90ms/step - loss: 2395994.0000 - val_loss: 2442234.2500\n","Epoch 29/30\n","34/34 [==============================] - 3s 86ms/step - loss: 2444016.7500 - val_loss: 2442877.7500\n","Epoch 30/30\n","34/34 [==============================] - 3s 87ms/step - loss: 2420604.2500 - val_loss: 2443188.5000\n","Model: \"vae\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," input_15 (InputLayer)          [(None, 22, 1000, 1  0           []                               \n","                                )]                                                                \n","                                                                                                  \n"," conv2d_28 (Conv2D)             (None, 22, 49, 32)   1312        ['input_15[0][0]']               \n","                                                                                                  \n"," leaky_re_lu_56 (LeakyReLU)     (None, 22, 49, 32)   0           ['conv2d_28[0][0]']              \n","                                                                                                  \n"," conv2d_29 (Conv2D)             (None, 1, 49, 64)    45120       ['leaky_re_lu_56[0][0]']         \n","                                                                                                  \n"," leaky_re_lu_57 (LeakyReLU)     (None, 1, 49, 64)    0           ['conv2d_29[0][0]']              \n","                                                                                                  \n"," flatten_14 (Flatten)           (None, 3136)         0           ['leaky_re_lu_57[0][0]']         \n","                                                                                                  \n"," dense_56 (Dense)               (None, 16)           50192       ['flatten_14[0][0]']             \n","                                                                                                  \n"," dense_58 (Dense)               (None, 2)            34          ['dense_56[0][0]']               \n","                                                                                                  \n"," dense_57 (Dense)               (None, 2)            34          ['dense_56[0][0]']               \n","                                                                                                  \n"," tf.__operators__.add_42 (TFOpL  (None, 2)           0           ['dense_58[0][0]']               \n"," ambda)                                                                                           \n","                                                                                                  \n"," lambda_14 (Lambda)             (None, 2)            0           ['dense_57[0][0]',               \n","                                                                  'tf.__operators__.add_42[0][0]']\n","                                                                                                  \n"," dense_59 (Dense)               (None, 3136)         9408        ['lambda_14[0][0]']              \n","                                                                                                  \n"," reshape_14 (Reshape)           (None, 1, 49, 64)    0           ['dense_59[0][0]']               \n","                                                                                                  \n"," conv2d_transpose_42 (Conv2DTra  (None, 22, 49, 64)  90176       ['reshape_14[0][0]']             \n"," nspose)                                                                                          \n","                                                                                                  \n"," leaky_re_lu_58 (LeakyReLU)     (None, 22, 49, 64)   0           ['conv2d_transpose_42[0][0]']    \n","                                                                                                  \n"," conv2d_transpose_43 (Conv2DTra  (None, 22, 1000, 32  81952      ['leaky_re_lu_58[0][0]']         \n"," nspose)                        )                                                                 \n","                                                                                                  \n"," leaky_re_lu_59 (LeakyReLU)     (None, 22, 1000, 32  0           ['conv2d_transpose_43[0][0]']    \n","                                )                                                                 \n","                                                                                                  \n"," conv2d_transpose_44 (Conv2DTra  (None, 22, 1000, 1)  801        ['leaky_re_lu_59[0][0]']         \n"," nspose)                                                                                          \n","                                                                                                  \n","==================================================================================================\n","Total params: 279,029\n","Trainable params: 279,029\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n","Epoch 1/30\n","17/17 [==============================] - 4s 179ms/step - loss: 2547222.7500 - val_loss: 2836182.7500\n","Epoch 2/30\n","17/17 [==============================] - 3s 163ms/step - loss: 4530004.0000 - val_loss: 2687555.5000\n","Epoch 3/30\n","17/17 [==============================] - 3s 163ms/step - loss: 2496693.2500 - val_loss: 2673512.7500\n","Epoch 4/30\n","17/17 [==============================] - 3s 171ms/step - loss: 2487484.0000 - val_loss: 2665947.7500\n","Epoch 5/30\n","17/17 [==============================] - 3s 168ms/step - loss: 2476366.5000 - val_loss: 2661267.7500\n","Epoch 6/30\n","17/17 [==============================] - 3s 168ms/step - loss: 2472141.7500 - val_loss: 2658501.5000\n","Epoch 7/30\n","17/17 [==============================] - 3s 163ms/step - loss: 2472206.0000 - val_loss: 2656846.0000\n","Epoch 8/30\n","17/17 [==============================] - 3s 162ms/step - loss: 2459573.7500 - val_loss: 2654226.7500\n","Epoch 9/30\n","17/17 [==============================] - 3s 169ms/step - loss: 2469026.7500 - val_loss: 2652717.2500\n","Epoch 10/30\n","17/17 [==============================] - 3s 164ms/step - loss: 2463027.5000 - val_loss: 2650579.5000\n","Epoch 11/30\n","17/17 [==============================] - 3s 163ms/step - loss: 2465560.2500 - val_loss: 2649123.2500\n","Epoch 12/30\n","17/17 [==============================] - 3s 171ms/step - loss: 2468232.5000 - val_loss: 2647006.5000\n","Epoch 13/30\n","17/17 [==============================] - 3s 167ms/step - loss: 2456579.7500 - val_loss: 2645802.0000\n","Epoch 14/30\n","17/17 [==============================] - 3s 171ms/step - loss: 2461569.0000 - val_loss: 2644188.5000\n","Epoch 15/30\n","17/17 [==============================] - 3s 168ms/step - loss: 2451832.7500 - val_loss: 2642439.2500\n","Epoch 16/30\n","17/17 [==============================] - 3s 168ms/step - loss: 2453781.5000 - val_loss: 2639670.0000\n","Epoch 17/30\n","17/17 [==============================] - 3s 164ms/step - loss: 2455340.2500 - val_loss: 2638250.0000\n","Epoch 18/30\n","17/17 [==============================] - 3s 169ms/step - loss: 2448936.5000 - val_loss: 2636143.7500\n","Epoch 19/30\n","17/17 [==============================] - 3s 165ms/step - loss: 2456850.2500 - val_loss: 2634460.0000\n","Epoch 20/30\n","17/17 [==============================] - 3s 163ms/step - loss: 2447454.0000 - val_loss: 2630788.7500\n","Epoch 21/30\n","17/17 [==============================] - 3s 169ms/step - loss: 2443145.7500 - val_loss: 2628890.2500\n","Epoch 22/30\n","17/17 [==============================] - 3s 169ms/step - loss: 2435142.2500 - val_loss: 2627575.0000\n","Epoch 23/30\n","17/17 [==============================] - 3s 163ms/step - loss: 2436868.2500 - val_loss: 2626412.2500\n","Epoch 24/30\n","17/17 [==============================] - 3s 165ms/step - loss: 2438473.7500 - val_loss: 2625589.5000\n","Epoch 25/30\n","17/17 [==============================] - 3s 164ms/step - loss: 2441086.2500 - val_loss: 2625099.5000\n","Epoch 26/30\n","17/17 [==============================] - 3s 164ms/step - loss: 2436670.5000 - val_loss: 2624350.5000\n","Epoch 27/30\n","17/17 [==============================] - 3s 161ms/step - loss: 2436677.5000 - val_loss: 2623694.5000\n","Epoch 28/30\n","17/17 [==============================] - 3s 162ms/step - loss: 2434809.0000 - val_loss: 2623476.2500\n","Epoch 29/30\n","17/17 [==============================] - 3s 169ms/step - loss: 2433024.5000 - val_loss: 2622672.7500\n","Epoch 30/30\n","17/17 [==============================] - 3s 169ms/step - loss: 2433825.0000 - val_loss: 2622435.7500\n"]}]},{"cell_type":"code","source":["for score in scores:\n","  print(\"lr = {\",score[0],\"} , bs = {\",score[1],\"} error = {\",score[2],\"}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wI0_S9uzPJcw","executionInfo":{"status":"ok","timestamp":1647308640178,"user_tz":420,"elapsed":138,"user":{"displayName":"ANDREA CASASSA SIAN","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05004144499949693318"}},"outputId":"53c6a1d9-436d-45ac-f8e2-476b488cf205"},"execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":["lr = { 0.001 } , bs = { 32 } error = { 109.692055 }\n","lr = { 0.001 } , bs = { 64 } error = { 110.24325 }\n","lr = { 0.001 } , bs = { 128 } error = { 109.64966 }\n","lr = { 0.0004 } , bs = { 32 } error = { 109.61293 }\n","lr = { 0.0004 } , bs = { 64 } error = { 109.5447 }\n","lr = { 0.0004 } , bs = { 128 } error = { 109.43475 }\n","lr = { 0.0006 } , bs = { 32 } error = { 109.564125 }\n","lr = { 0.0006 } , bs = { 64 } error = { 109.62864 }\n","lr = { 0.0006 } , bs = { 128 } error = { 109.71559 }\n"]}]},{"cell_type":"markdown","source":["## Generate synthetic data"],"metadata":{"id":"HZJQwIGFnwaW"}},{"cell_type":"code","source":["synthetic_data = vae.predict(X_VAE_train)\n","print(UT.int_shape(synthetic_data))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aV8PPxudniRd","executionInfo":{"status":"ok","timestamp":1647308164858,"user_tz":420,"elapsed":1661,"user":{"displayName":"ANDREA CASASSA SIAN","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05004144499949693318"}},"outputId":"0f28032f-fc1b-46b6-9979-999a78e58082"},"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["(2115, 22, 1000, 1)\n"]}]},{"cell_type":"markdown","source":["## Visualize the new data"],"metadata":{"id":"cWUS72b0dxUa"}},{"cell_type":"code","source":["synthetic_data = synthetic_data.reshape(synthetic_data.shape[0],synthetic_data.shape[1],synthetic_data.shape[2])\n","print(synthetic_data.shape)\n","\n","#Visualize the data on for channel 8\n","ch_data = synthetic_data[:,8,:]\n","\n","#Class 1\n","class_0_ind = np.where(y_train_valid == 0)\n","ch_data_class_0 = ch_data[class_0_ind]\n","avg_ch_data_class_0 = np.mean(ch_data_class_0,axis=0)\n","\n","#Class 2\n","class_1_ind = np.where(y_train_valid == 1)\n","ch_data_class_1 = ch_data[class_1_ind]\n","avg_ch_data_class_1 = np.mean(ch_data_class_1,axis=0)\n","\n","#Class 3\n","class_2_ind = np.where(y_train_valid == 2)\n","ch_data_class_2 = ch_data[class_2_ind]\n","avg_ch_data_class_2 = np.mean(ch_data_class_2,axis=0)\n","\n","#Class 4\n","class_3_ind = np.where(y_train_valid == 3)\n","ch_data_class_3 = ch_data[class_3_ind]\n","avg_ch_data_class_3 = np.mean(ch_data_class_3,axis=0)\n","\n","plt.plot(np.arange(1000),avg_ch_data_class_0)\n","plt.plot(np.arange(1000),avg_ch_data_class_1)\n","plt.plot(np.arange(1000),avg_ch_data_class_2)\n","plt.plot(np.arange(1000),avg_ch_data_class_3)\n","plt.axvline(x=500, label='line at t=500',c='cyan')\n","plt.title(\"Signal\")\n","\n","plt.legend([\"Cue Onset left\", \"Cue Onset right\", \"Cue onset foot\", \"Cue onset tongue\"])\n","\n","#NOTE: we use the same labels y_train_valid because we've generated 2115 synthetic data (one-to-one mapping)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":315},"id":"eioNKRqZdvgb","executionInfo":{"status":"ok","timestamp":1647308824520,"user_tz":420,"elapsed":626,"user":{"displayName":"ANDREA CASASSA SIAN","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05004144499949693318"}},"outputId":"22706574-c8a4-478f-acb9-608ea025b637"},"execution_count":30,"outputs":[{"output_type":"stream","name":"stdout","text":["(2115, 22, 1000)\n"]},{"output_type":"execute_result","data":{"text/plain":["<matplotlib.legend.Legend at 0x7f6ca4ed9950>"]},"metadata":{},"execution_count":30},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","source":["## Save the synthetic data in a file"],"metadata":{"id":"YMvqVCcPhlOz"}},{"cell_type":"code","source":["with open('synthetic_data.npy', 'wb') as f:\n","  np.save(f, synthetic_data)"],"metadata":{"id":"B6eipeAhhkqK","executionInfo":{"status":"ok","timestamp":1647308313964,"user_tz":420,"elapsed":3354,"user":{"displayName":"ANDREA CASASSA SIAN","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05004144499949693318"}}},"execution_count":28,"outputs":[]},{"cell_type":"markdown","source":["## Appendix: draft code"],"metadata":{"id":"HWn0U8xt9YKd"}},{"cell_type":"code","source":["# def encoder(input_encoder):\n","\n","#   inputs = keras.Input(shape=input_shape[1:])\n","#   x = inputs\n","\n","#   #Block1\n","#   x = layers.Conv2D(32,kernel_size=(1,40),strides=(1,20))(x)\n","#   x = layers.BatchNormalization()(x)\n","#   x = layers.LeakyReLU()(x)\n","\n","#   #Block2\n","#   x = layers.Conv2D(64,kernel_size=(22,1))(x)\n","#   x = layers.BatchNormalization()(x)\n","#   x = layers.LeakyReLU()(x)\n","\n","#   #shape = 1,49,64\n","#   useful_shape = UT.int_shape(x)\n","\n","#   #Final block\n","#   x = layers.Flatten()(x)\n","#   x = layers.Dense(16,activation='relu')(x)\n","\n","#   z_mean = layers.Dense(2)(x)\n","#   z_log_var = layers.Dense(2)(x)\n","#   z_log_var += 1e-6 #add an epsilon so that it's not zero\n","\n","\n","#   model = tf.keras.Model(inputs, (z_mean, z_log_var), name=\"Encoder\")\n","\n","#   model.summary()\n","\n","#   return (model, z_mean, z_log_var)"],"metadata":{"id":"Oe_Yk5wecjcV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# def decoder(input_decoder):\n","\n","#   inputs = keras.Input(shape=(2,))\n","#   x = inputs\n","\n","#   #Initial block\n","#   x = layers.Dense(1*49*64)(x)\n","#   x = layers.Reshape((1,49,64))(x)\n","\n","#   # Block1\n","#   x = layers.Conv2DTranspose(64, kernel_size=(22,1))(x)\n","#   x = layers.BatchNormalization()(x)\n","#   x = layers.LeakyReLU()(x)\n","\n","#   #Block2\n","#   x = layers.Conv2DTranspose(32, kernel_size=(1,40), strides= (1,20))(x)\n","#   x = layers.BatchNormalization()(x)\n","#   x = layers.LeakyReLU()(x)\n","\n","#   #Final block\n","#   out = layers.Conv2DTranspose(1, 3, 1,padding='same', activation='sigmoid')(x)\n","\n","#   model = tf.keras.Model(inputs, out, name = \"Decoder\")\n","\n","#   model.summary()\n","\n","#   return (model, out)\n","\n"],"metadata":{"id":"X1BJwCdC5_dL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# @tf.function\n","# def train_step(data):\n","\n","#     with tf.GradientTape() as enc, tf.GradientTape() as dec:\n","        \n","\n","#         e, mean, log_var = encoder(data)\n","#         latent = sampling(mean, log_var)\n","\n","#         d, generated_data = decoder(latent)\n","\n","#         generated_data = tf.cast(generated_data, tf.float64)\n","\n","#         loss = vae_loss(data, generated_data, mean, log_var)\n","#         print(loss)\n","       \n","\n","#     gradients_of_enc = enc.gradient(loss, e.trainable_variables)\n","#     gradients_of_dec = dec.gradient(loss, d.trainable_variables)\n"," \n","#     optimizer.apply_gradients(zip(gradients_of_enc, e.trainable_variables))\n","#     optimizer.apply_gradients(zip(gradients_of_dec, d.trainable_variables))\n","\n","#     return loss\n"],"metadata":{"id":"YzEMJgdSXOv8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# def train_step(data):\n","  \n","#   vae, out, mean, log_var = VAE(data)\n","#   loss = vae_loss(data, out, mean, log_var)\n","\n","#   vae.add_loss(loss)\n","#   vae.compile(optimizer,loss=None)\n","  \n","#   return loss"],"metadata":{"id":"VzBWK4PE96G_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# def sampling(args):   \n","#     mean, log_var = args\n","#     batch = UT.shape(mean)[0]\n","#     dim = UT.int_shape(mean)[1]\n","#     epsilon = UT.random_normal(shape=(batch, dim))\n","#     return mean + UT.exp(0.5 * log_var) * epsilon "],"metadata":{"id":"JZ8ljM0y3uaT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ## VAE\n","\n","# #ENCODER\n","# inp = Input(shape=inp)\n","# x = inp\n","# x = Conv2D(filters=filters_1,kernel_size=(1, 50),strides=(1,25),)(x)\n","# x = ReLU()(x)\n","# x = Conv2D(filters=filters_2,kernel_size=(22, 1),)(x)\n","# x = ReLU()(x)\n","# print(UT.int_shape(x))\n","# x = Flatten()(x)\n","# x = Dense(16, activation='relu')(x)\n","# print(UT.int_shape(x))\n","# mean = Dense(hidden_dim)(x)\n","# log_var = Dense(hidden_dim)(x)\n","\n","# #SAMPLING\n","# z = Lambda(sampling, output_shape=(hidden_dim,),)([mean, log_var]) \n","# encoder = Model(inp, [mean, log_var, z])\n","\n","# #DECODER\n","# dec_inp = Input(shape=(hidden_dim,))\n","# x = Dense(22 * 9 * 32, activation='relu')(dec_inp)\n","# x = Reshape((22, 9, 32))(x)\n","# print(UT.int_shape(x))\n","# x = Conv2DTranspose(filters=filters_2,kernel_size=(22, 1),activation='relu',)(x)\n","# x = Conv2DTranspose(filters=filters_1,kernel_size=(1, 50),activation='relu',strides=(1,25))(x)\n","# out = Conv2DTranspose(filters=1,kernel_size=kernel_size,padding='same',)(x)\n","# print(UT.int_shape(out))\n","# decoder = Model(dec_inp, out)\n","\n","# #VAE\n","# out = decoder(encoder(inp)[2])\n","# vae = Model(inp, out)"],"metadata":{"id":"kmxyJDCx30xn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# #TRAINING\n","\n","# r_loss = mse(UT.flatten(inp), UT.flatten(out))\n","# r_loss *= 22 * 50\n","# kl_loss = 1 + log_var - UT.square(mean) - UT.exp(log_var)\n","# kl_loss = UT.sum(kl_loss, axis=-1)\n","# kl_loss *= -0.5\n","# vae_loss = UT.mean(r_loss + kl_loss)\n","# vae.add_loss(vae_loss)\n","# optimizer = Adam(learning_rate=0.001, beta_1=0.1, beta_2=0.999, amsgrad=False)\n","\n","# vae.compile(optimizer=optimizer, loss=None)\n","\n","# loss_record = vae.fit(x = X_train_valid,epochs=epochs,batch_size=batch_size,validation_data=(X_test, None))"],"metadata":{"id":"7TCpozX230jR"},"execution_count":null,"outputs":[]}]}